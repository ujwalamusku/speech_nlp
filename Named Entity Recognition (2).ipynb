{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "spacy_nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = spacy_nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -->  --> SPACE\n",
      "Asian --> amod --> ADJ\n",
      "shares --> nsubj --> NOUN\n",
      "skidded --> ROOT --> VERB\n",
      "on --> prep --> ADP\n",
      "Tuesday --> pobj --> PROPN\n",
      "after --> mark --> ADP\n",
      "a --> det --> DET\n",
      "rout --> nsubj --> NOUN\n",
      "in --> prep --> ADP\n",
      "tech --> compound --> NOUN\n",
      "stocks --> pobj --> NOUN\n",
      "put --> advcl --> VERB\n",
      "Wall --> compound --> PROPN\n",
      "Street --> dobj --> PROPN\n",
      "to --> prep --> ADP\n",
      "the --> det --> DET\n",
      "sword --> pobj --> NOUN\n",
      ", --> punct --> PUNCT\n",
      "while --> mark --> SCONJ\n",
      "a --> det --> DET\n",
      "\n",
      " -->  --> SPACE\n",
      "sharp --> amod --> ADJ\n",
      "drop --> nsubj --> NOUN\n",
      "in --> prep --> ADP\n",
      "oil --> compound --> NOUN\n",
      "prices --> pobj --> NOUN\n",
      "and --> cc --> CCONJ\n",
      "political --> amod --> ADJ\n",
      "risks --> conj --> NOUN\n",
      "in --> prep --> ADP\n",
      "Europe --> pobj --> PROPN\n",
      "pushed --> advcl --> VERB\n",
      "the --> det --> DET\n",
      "dollar --> dobj --> NOUN\n",
      "to --> prep --> ADP\n",
      "16-month --> nummod --> NUM\n",
      "highs --> pobj --> NOUN\n",
      "as --> mark --> SCONJ\n",
      "investors --> nsubj --> NOUN\n",
      "dumped --> advcl --> VERB\n",
      "\n",
      " -->  --> SPACE\n",
      "riskier --> amod --> ADJ\n",
      "assets --> dobj --> NOUN\n",
      ". --> punct --> PUNCT\n",
      "MSCI --> nmod --> PROPN\n",
      "’s --> punct --> PART\n",
      "broadest --> amod --> ADJ\n",
      "index --> nsubj --> NOUN\n",
      "of --> prep --> ADP\n",
      "Asia --> compound --> PROPN\n",
      "- --> punct --> PUNCT\n",
      "Pacific --> compound --> PROPN\n",
      "shares --> pobj --> NOUN\n",
      "outside --> prep --> ADP\n",
      "Japan --> pobj --> PROPN\n",
      "dropped --> ROOT --> VERB\n",
      "1.7 --> nummod --> NUM\n",
      "percent --> npadvmod --> NOUN\n",
      "to --> prep --> ADP\n",
      "a --> det --> DET\n",
      "1 --> compound --> NUM\n",
      "- --> punct --> SYM\n",
      "1/2 --> nummod --> NUM\n",
      "\n",
      " -->  --> SPACE\n",
      "week --> compound --> NOUN\n",
      "trough --> pobj --> NOUN\n",
      ", --> punct --> PUNCT\n",
      "with --> prep --> ADP\n",
      "Australian --> amod --> ADJ\n",
      "shares --> nsubj --> NOUN\n",
      "sinking --> pcomp --> VERB\n",
      "1.6 --> nummod --> NUM\n",
      "percent --> dobj --> NOUN\n",
      ". --> punct --> PUNCT\n",
      "Japan --> ROOT --> PROPN\n",
      "’s --> punct --> PART\n",
      "Nikkei --> nsubj --> PROPN\n",
      "dived --> ROOT --> VERB\n",
      "3.1 --> nummod --> NUM\n",
      "percent --> dobj --> NOUN\n",
      "led --> acl --> VERB\n",
      "by --> agent --> ADP\n",
      "losses --> pobj --> NOUN\n",
      "in --> prep --> ADP\n",
      "\n",
      " -->  --> SPACE\n",
      "electric --> amod --> ADJ\n",
      "machinery --> compound --> NOUN\n",
      "makers --> pobj --> NOUN\n",
      "and --> cc --> CCONJ\n",
      "suppliers --> conj --> NOUN\n",
      "of --> prep --> ADP\n",
      "Apple --> nmod --> PROPN\n",
      "’s --> punct --> PART\n",
      "iphone --> compound --> NOUN\n",
      "parts --> pobj --> NOUN\n",
      ". --> punct --> PUNCT\n",
      "Sterling --> nsubj --> NOUN\n",
      "fell --> ccomp --> VERB\n",
      "to --> prep --> ADP\n",
      "$ --> nmod --> SYM\n",
      "1.286 --> pobj --> NUM\n",
      "after --> mark --> ADP\n",
      "three --> nummod --> NUM\n",
      "straight --> amod --> ADJ\n",
      "\n",
      " -->  --> SPACE\n",
      "sessions --> nsubj --> NOUN\n",
      "of --> prep --> ADP\n",
      "losses --> pobj --> NOUN\n",
      "took --> advcl --> VERB\n",
      "it --> dobj --> PRON\n",
      "to --> prep --> ADP\n",
      "the --> det --> DET\n",
      "lowest --> pobj --> ADJ\n",
      "since --> advmod --> SCONJ\n",
      "Nov.1 --> punct --> ADV\n",
      "as --> mark --> SCONJ\n",
      "there --> expl --> PRON\n",
      "were --> advcl --> AUX\n",
      "still --> advmod --> ADV\n",
      "considerable --> amod --> ADJ\n",
      "unresolved --> amod --> ADJ\n",
      "issues --> attr --> NOUN\n",
      "with --> prep --> ADP\n",
      "the --> det --> DET\n",
      "\n",
      " -->  --> SPACE\n",
      "European --> compound --> PROPN\n",
      "Union --> pobj --> PROPN\n",
      "over --> prep --> ADP\n",
      "Brexit --> pobj --> PROPN\n",
      ", --> punct --> PUNCT\n",
      "British --> amod --> ADJ\n",
      "Prime --> compound --> PROPN\n",
      "Minister --> compound --> PROPN\n",
      "Theresa --> compound --> PROPN\n",
      "May --> nsubj --> PROPN\n",
      "said --> ROOT --> VERB\n",
      "on --> prep --> ADP\n",
      "Monday --> pobj --> PROPN\n",
      ". --> punct --> PUNCT\n"
     ]
    }
   ],
   "source": [
    "# print token, dependency, POS tag \n",
    "for tok in document: \n",
    "  print(tok.text, \"-->\",tok.dep_,\"-->\", tok.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: NORP, Value: Asian\n",
      "Type: DATE, Value: Tuesday\n",
      "Type: LOC, Value: Europe\n",
      "Type: LOC, Value: Asia-Pacific\n",
      "Type: GPE, Value: Japan\n",
      "Type: PERCENT, Value: 1.7 percent\n",
      "Type: CARDINAL, Value: 1-1/2\n",
      "Type: DATE, Value: week trough\n",
      "Type: NORP, Value: Australian\n",
      "Type: PERCENT, Value: 1.6 percent\n",
      "Type: GPE, Value: Japan\n",
      "Type: PERCENT, Value: 3.1 percent\n",
      "Type: ORG, Value: Apple\n",
      "Type: MONEY, Value: 1.286\n",
      "Type: CARDINAL, Value: three\n",
      "Type: ORG, Value: European Union\n",
      "Type: GPE, Value: Brexit\n",
      "Type: NORP, Value: British\n",
      "Type: PERSON, Value: Theresa May\n",
      "Type: DATE, Value: Monday\n"
     ]
    }
   ],
   "source": [
    "for element in document.ents:\n",
    "    print('Type: %s, Value: %s' % (element.label_, element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_matcher(doc): \n",
    "  x = '' \n",
    "  y = '' \n",
    "  \n",
    "  # iterate through all the tokens in the input sentence \n",
    "  for i,tok in enumerate(doc): \n",
    "    # extract subject \n",
    "    if tok.dep_.find(\"subjpass\") == True: \n",
    "      y = tok.text \n",
    "      \n",
    "    # extract object \n",
    "    if tok.dep_.endswith(\"obj\") == True: \n",
    "      x = tok.text \n",
    "      \n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Monday', '')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtree_matcher(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan dropped 1.7\n"
     ]
    }
   ],
   "source": [
    "#define the pattern \n",
    "from spacy.matcher import Matcher \n",
    "matcher = Matcher(spacy_nlp.vocab)\n",
    "pattern = [\n",
    "           {'POS':'NOUN','OP':\"?\"},\n",
    "           {'POS':'PRON','OP':\"?\"},\n",
    "           {'POS':'PROPN','OP':\"?\"},    \n",
    "           {'POS':'VERB'},\n",
    "           {'DEP':'nummod','OP':\"?\"},\n",
    "           {'DEP':'nummod'}\n",
    "           ] \n",
    "           \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(document) \n",
    "span = document[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shares\n"
     ]
    }
   ],
   "source": [
    "#define the pattern \n",
    "from spacy.matcher import Matcher \n",
    "matcher = Matcher(spacy_nlp.vocab)\n",
    "pattern = [\n",
    "           {'POS':'NOUN'}, \n",
    "           {'DEP':'nummod','OP':\"?\"}\n",
    "           {'POS':'VERB'},\n",
    "           {'DEP':'nummod','OP':\"?\"}\n",
    "           ] \n",
    "           \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(document) \n",
    "span = document[matches[0][1]:matches[0][2]] \n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abhishek's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monali\\\\Desktop\\\\Speech to text'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import en_core_web_sm\n",
    "spacy_nlp = en_core_web_sm.load()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: PERSON, Value: Tim\n",
      "Type: CARDINAL, Value: 5\n",
      "Type: DATE, Value: this quarter\n",
      "Type: CARDINAL, Value: 5\n",
      "Type: PRODUCT, Value: Boots, Dell\n",
      "Type: PERSON, Value: Tesco Mobile\n",
      "Type: ORG, Value: Peugeot\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: PERSON, Value: Boots\n",
      "Type: ORG, Value: Create\n",
      "Type: ORG, Value: MediaCom\n",
      "Type: PERSON, Value: Jivox\n",
      "Type: GPE, Value: UK\n",
      "Type: PERSON, Value: Bob\n",
      "Type: PERSON, Value: Dell\n",
      "Type: PERSON, Value: Dell\n",
      "Type: GPE, Value: US\n",
      "Type: ORG, Value: Dell\n",
      "Type: CARDINAL, Value: Q1\n",
      "Type: NORP, Value: European\n",
      "Type: CARDINAL, Value: three\n",
      "Type: PERSON, Value: this Gavin Reeder\n",
      "Type: MONEY, Value: friendâ€™\n",
      "Type: PRODUCT, Value: Fran\n",
      "Type: PERSON, Value: aheadÂ\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: TIME, Value: this morning\n",
      "Type: ORG, Value: Tesco Mobile\n",
      "Type: ORG, Value: Peugeot\n",
      "Type: CARDINAL, Value: ™\n",
      "Type: DATE, Value: this quarter\n",
      "Type: ORG, Value: Tesco\n",
      "Type: WORK_OF_ART, Value: Â£500k\n",
      "Type: ORG, Value: Peugeot\n",
      "Type: DATE, Value: last year\n",
      "Type: MONEY, Value: a penny\n",
      "Type: DATE, Value: 2018\n",
      "Type: PERSON, Value: Raj\n",
      "Type: ORG, Value: Tesco Mobile\n",
      "Type: ORG, Value: Motion\n",
      "Type: LOC, Value: Europe\n",
      "Type: PERSON, Value: Damien\n",
      "Type: CARDINAL, Value: ™\n",
      "Type: CARDINAL, Value: one\n",
      "Type: ORG, Value: Tesco\n",
      "Type: PERSON, Value: Damien\n",
      "Type: ORG, Value: Freddie\n",
      "Type: PERSON, Value: Damien\n",
      "Type: ORG, Value: Freddie\n",
      "Type: CARDINAL, Value: ™\n",
      "Type: CARDINAL, Value: 5minutes\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: ORG, Value: Peugeot\n",
      "Type: DATE, Value: next week\n",
      "Type: CARDINAL, Value: ™\n",
      "Type: PERSON, Value: Luke\n",
      "Type: ORG, Value: DV360\n",
      "Type: ORG, Value: Quantcast\n",
      "Type: ORG, Value: Captify\n",
      "Type: PERSON, Value: Luke\n",
      "Type: DATE, Value: 2020\n",
      "Type: CARDINAL, Value: notesâ€\n",
      "Type: CARDINAL, Value: secondsâ€\n",
      "Type: ORG, Value: ADH\n",
      "Type: ORG, Value: ADH\n",
      "Type: PERSON, Value: Ads\n",
      "Type: PERSON, Value: Tom Richards\n",
      "Type: DATE, Value: last week\n",
      "Type: ORG, Value: Google\n",
      "Type: ORDINAL, Value: first\n",
      "Type: PERSON, Value: Tom\n",
      "Type: ORG, Value: ADH\n",
      "Type: GPE, Value: Bangalore\n",
      "Type: PERSON, Value: Bob\n",
      "Type: MONEY, Value: thatâ€™s\n",
      "Type: PERSON, Value: Abhishek Chakraborty\n",
      "Type: DATE, Value: last month\n",
      "Type: PERSON, Value: Tim\n",
      "Type: PERSON, Value: Tom\n",
      "Type: TIME, Value: a minute\n",
      "Type: PERSON, Value: Gavin\n",
      "Type: PERSON, Value: Tim\n",
      "Type: PERSON, Value: Damien\n",
      "Type: ORG, Value: Tesco\n",
      "Type: PERSON, Value: Tim\n",
      "Type: ORG, Value: Tom & Abhishek\n",
      "Type: ORG, Value: ADH\n",
      "Type: PERSON, Value: Adidas\n",
      "Type: PERSON, Value: Giles\n",
      "weather conditions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import en_core_web_sm\n",
    "spacy_nlp = en_core_web_sm.load()\n",
    "\n",
    "os.getcwd()\n",
    "#os.chdir('C:\\\\Users\\\\abhishekpandey\\\\Desktop\\\\Hack19')\n",
    "\n",
    "text_file = open('text_block.txt', 'r')\n",
    "article_text = text_file.read()\n",
    "text_file.close()\n",
    "\n",
    "article_document = spacy_nlp(article_text)\n",
    "\n",
    "elements_in_text = []\n",
    "for element in article_document.ents:\n",
    "    print('Type: %s, Value: %s' % (element.label_, element))\n",
    "    temp_list = []\n",
    "    temp_list.append(element.label_)\n",
    "    temp_list.append(element)\n",
    "    \n",
    "    elements_in_text.append(temp_list)\n",
    "\n",
    "\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "matcher = Matcher(spacy_nlp.vocab)\n",
    "pattern = [ {'POS':'NOUN'}, \n",
    "          \n",
    "           {'POS':'VERB','OP':\"?\"},\n",
    "           {'POS':'NOUN'}\n",
    "          ] \n",
    "           \n",
    "matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "matches = matcher(article_document) \n",
    "span = article_document[matches[0][1]:matches[0][2]] \n",
    "\n",
    "\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_is_speech = pd.DataFrame(elements_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>(Tim)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DATE</td>\n",
       "      <td>(this, quarter)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>(Boots, ,, Dell)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>(Tim)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(Tom, &amp;, Abhishek)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>ORG</td>\n",
       "      <td>(ADH)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>(Adidas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>(Giles)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                   1\n",
       "0     PERSON               (Tim)\n",
       "1   CARDINAL                 (5)\n",
       "2       DATE     (this, quarter)\n",
       "3   CARDINAL                 (5)\n",
       "4    PRODUCT    (Boots, ,, Dell)\n",
       "..       ...                 ...\n",
       "86    PERSON               (Tim)\n",
       "87       ORG  (Tom, &, Abhishek)\n",
       "88       ORG               (ADH)\n",
       "89    PERSON            (Adidas)\n",
       "90    PERSON             (Giles)\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_is_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
